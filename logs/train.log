C:\Users\cwchan\Documents\whisper-demo\.venv\Scripts\python.exe C:\Users\cwchan\Documents\whisper-demo\demo.py --train 
argument list:  ['C:\\Users\\cwchan\\Documents\\whisper-demo\\demo.py', '--train']
'fine-tuning whisper, and this would take long time ...'
...../root/miniconda3/envs/whisper/lib/python3.10/site-packages/torch_npu/dynamo/__init__.py:18: UserWarning: Register eager implementation for the 'npu' backend of dynamo, as torch_npu was not compiled with torchair.
warnings.warn(
/root/miniconda3/envs/whisper/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:164: ImportWarning:
*************************************************************************************************************
The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
The backend in torch.distributed.init_process_group set to hccl now..
The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
The device parameters have been replaced with npu in the function below:
torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty
*************************************************************************************************************

warnings.warn(msg, ImportWarning)
..argument list:  ['whisper-finetune.py']
Downloading data: 12.2kB [00:00, 21.2MB/s]
Downloading data: 100%|████████████████████| 73.5M/73.5M [00:05<00:00, 14.3MB/s]
Downloading data: 100%|████████████████████| 63.1M/63.1M [00:04<00:00, 14.2MB/s]
Downloading data: 100%|████████████████████| 68.3M/68.3M [00:06<00:00, 10.4MB/s]
Downloading data: 100%|██████████████████████| 641M/641M [00:19<00:00, 32.7MB/s]
Downloading data: 100%|████████████████████| 45.0M/45.0M [00:04<00:00, 10.3MB/s]
Downloading data: 100%|███████████████████████| 709k/709k [00:00<00:00, 890kB/s]
Downloading data: 100%|███████████████████████| 514k/514k [00:01<00:00, 482kB/s]
Downloading data: 100%|██████████████████████| 503k/503k [00:00<00:00, 2.24MB/s]
Downloading data: 100%|████████████████████| 5.39M/5.39M [00:00<00:00, 13.7MB/s]
Downloading data: 100%|██████████████████████| 414k/414k [00:00<00:00, 2.19MB/s]
Generating train split: 0 examples [00:00, ? examples/s]
Reading metadata...: 2877it [00:00, 94050.90it/s]
Generating train split: 2877 examples [00:01, 2200.08 examples/s]
Generating validation split: 0 examples [00:00, ? examples/s]
Reading metadata...: 2419it [00:00, 106233.27it/s]
Generating validation split: 2419 examples [00:01, 2263.82 examples/s]
Generating test split: 0 examples [00:00, ? examples/s]
Reading metadata...: 2438it [00:00, 108058.81it/s]
Generating test split: 2438 examples [00:01, 2224.35 examples/s]
Generating other split: 0 examples [00:00, ? examples/s]
Reading metadata...: 0it [00:00, ?it/s]
Reading metadata...: 10211it [00:00, 102099.63it/s]
Reading metadata...: 25100it [00:00, 102459.60it/s]
Generating other split: 25100 examples [00:11, 2127.60 examples/s]
Generating invalidated split: 0 examples [00:00, ? examples/s]
Reading metadata...: 1559it [00:00, 99672.58it/s]
Generating invalidated split: 1559 examples [00:00, 2095.86 examples/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
.Running long task on converting dataset ...
Map (num_proc=64): 100%|█████████████| 5296/5296 [14:43<00:00,  5.99 examples/s]
Map (num_proc=64): 100%|█████████████| 2438/2438 [05:38<00:00,  7.20 examples/s]
.DatasetDict({
train: Dataset({
features: ['input_features', 'labels'],
num_rows: 5296
})
test: Dataset({
features: ['input_features', 'labels'],
num_rows: 2438
})
})
Downloading builder script: 4.49kB [00:00, 6.80MB/s]
.The file '/root/demo/.cache.serialized_data_cache.zip' exists.
The data has been loaded from /root/demo/.cache.serialized_data_cache.zip
!!!Debugging, sampling 100 data points only. Remove this for production case!!!
.........................<frozen importlib._bootstrap>:671: ImportWarning: TBEMetaPathLoader.exec_module() not found; falling back to load_module()
.........Running long task on training the model  ...
Current timestamp: 2024-06-20 20:58:15
....0%|                                                   | 0/160 [00:00<?, ?it/s]`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...
............[W AmpForeachNonFiniteCheckAndUnscaleKernelNpuOpApi.cpp:104] Warning: Non finite check and unscale on NPU device! (function operator())
{'loss': 2.2926, 'learning_rate': 1e-05, 'epoch': 2.56}
...10%|████▏                                     | 16/160 [03:23<30:56, 12.89s/it]
..0%|                                                    | 0/50 [00:00<?, ?it/s]
..4%|█▊                                          | 2/50 [00:02<00:49,  1.03s/it]
...6%|██▋                                         | 3/50 [00:04<01:11,  1.51s/it]
.8%|███▌                                        | 4/50 [00:06<01:30,  1.97s/it]
..10%|████▍                                       | 5/50 [00:08<01:17,  1.72s/it]
.12%|█████▎                                      | 6/50 [00:09<01:11,  1.62s/it]
..14%|██████▏                                     | 7/50 [00:11<01:06,  1.56s/it]
...16%|███████                                     | 8/50 [00:12<01:06,  1.58s/it]
.18%|███████▉                                    | 9/50 [00:15<01:21,  2.00s/it]
..20%|████████▌                                  | 10/50 [00:17<01:17,  1.95s/it]
..22%|█████████▍                                 | 11/50 [00:19<01:14,  1.91s/it]
.24%|██████████▎                                | 12/50 [00:20<01:09,  1.82s/it]
..26%|███████████▏                               | 13/50 [00:22<01:03,  1.71s/it]
..28%|████████████                               | 14/50 [00:24<01:06,  1.84s/it]
..30%|████████████▉                              | 15/50 [00:26<01:05,  1.86s/it]
.32%|█████████████▊                             | 16/50 [00:27<00:59,  1.75s/it]
..34%|██████████████▌                            | 17/50 [00:29<00:54,  1.66s/it]
..36%|███████████████▍                           | 18/50 [00:31<00:55,  1.72s/it]
.38%|████████████████▎                          | 19/50 [00:32<00:53,  1.73s/it]
..40%|█████████████████▏                         | 20/50 [00:34<00:49,  1.64s/it]
.42%|██████████████████                         | 21/50 [00:36<00:47,  1.64s/it]
..44%|██████████████████▉                        | 22/50 [00:37<00:44,  1.59s/it]
...46%|███████████████████▊                       | 23/50 [00:38<00:41,  1.54s/it]
.48%|████████████████████▋                      | 24/50 [00:41<00:50,  1.92s/it]
.50%|█████████████████████▌                     | 25/50 [00:43<00:44,  1.76s/it]
..52%|██████████████████████▎                    | 26/50 [00:44<00:39,  1.63s/it]
..54%|███████████████████████▏                   | 27/50 [00:46<00:38,  1.67s/it]
.56%|████████████████████████                   | 28/50 [00:47<00:34,  1.58s/it]
.58%|████████████████████████▉                  | 29/50 [00:48<00:30,  1.47s/it]
..60%|█████████████████████████▊                 | 30/50 [00:50<00:30,  1.54s/it]
.62%|██████████████████████████▋                | 31/50 [00:51<00:27,  1.47s/it]
..64%|███████████████████████████▌               | 32/50 [00:53<00:25,  1.44s/it]
.66%|████████████████████████████▍              | 33/50 [00:55<00:27,  1.61s/it]
..68%|█████████████████████████████▏             | 34/50 [00:56<00:24,  1.53s/it]
..70%|██████████████████████████████             | 35/50 [00:57<00:22,  1.47s/it]
.72%|██████████████████████████████▉            | 36/50 [00:59<00:22,  1.61s/it]
..............74%|███████████████████████████████▊           | 37/50 [01:01<00:21,  1.63s/it]
..76%|████████████████████████████████▋          | 38/50 [01:15<01:03,  5.31s/it]
.78%|█████████████████████████████████▌         | 39/50 [01:16<00:45,  4.12s/it]
.80%|██████████████████████████████████▍        | 40/50 [01:18<00:32,  3.30s/it]
..82%|███████████████████████████████████▎       | 41/50 [01:19<00:24,  2.75s/it]
.84%|████████████████████████████████████       | 42/50 [01:20<00:18,  2.33s/it]
..86%|████████████████████████████████████▉      | 43/50 [01:22<00:14,  2.03s/it]
.88%|█████████████████████████████████████▊     | 44/50 [01:23<00:11,  1.84s/it]
..90%|██████████████████████████████████████▋    | 45/50 [01:25<00:09,  1.83s/it]
..92%|███████████████████████████████████████▌   | 46/50 [01:27<00:07,  1.77s/it]
..94%|████████████████████████████████████████▍  | 47/50 [01:28<00:05,  1.71s/it]
.96%|█████████████████████████████████████████▎ | 48/50 [01:30<00:03,  1.83s/it]
.98%|██████████████████████████████████████████▏| 49/50 [01:32<00:01,  1.69s/it]
100%|███████████████████████████████████████████| 50/50 [01:32<00:00,  1.36s/it]
compute_metrics ...
Current timestamp: 2024-06-20 21:03:15

running: tokenizer.batch_decode(pred_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:03:15
...................................................................................
running: label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:04:38
...............................................................................
running: wer = 100 * metric.compute(predictions=pred_str, references=label_str)...
Current timestamp: 2024-06-20 21:05:57

{'eval_loss': 0.26915648579597473, 'eval_wer': 102.88461538461537, 'eval_runtime': 257.6941, 'eval_samples_per_second': 0.388, 'eval_steps_per_second': 0.194, 'epoch': 2.56}
10%|████▏                                     | 16/160 [07:41<30:56, 12.89s/it]
100%|███████████████████████████████████████████| 50/50 [04:14<00:00,  1.36s/it]
Checkpoint destination directory /mnt/remote/models/whisper/whisper-large-v3-yue/checkpoint-16 already exists and is non-empty.Saving will proceed but saved results may be invalid.
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'begin_suppress_tokens': [220, 50256]}
{'loss': 0.0499, 'learning_rate': 8.888888888888888e-06, 'epoch': 5.12}
..20%|████████▍                                 | 32/160 [11:40<27:09, 12.73s/it]
..0%|                                                    | 0/50 [00:00<?, ?it/s]
...4%|█▊                                          | 2/50 [00:02<00:51,  1.07s/it]
..6%|██▋                                         | 3/50 [00:04<01:13,  1.56s/it]
..8%|███▌                                        | 4/50 [00:06<01:21,  1.78s/it]
.10%|████▍                                       | 5/50 [00:08<01:20,  1.79s/it]
..12%|█████▎                                      | 6/50 [00:10<01:19,  1.80s/it]
..14%|██████▏                                     | 7/50 [00:12<01:18,  1.82s/it]
...16%|███████                                     | 8/50 [00:13<01:17,  1.86s/it]
...18%|███████▉                                    | 9/50 [00:16<01:30,  2.20s/it]
..20%|████████▌                                  | 10/50 [00:19<01:32,  2.31s/it]
..22%|█████████▍                                 | 11/50 [00:21<01:22,  2.13s/it]
..24%|██████████▎                                | 12/50 [00:23<01:19,  2.09s/it]
..26%|███████████▏                               | 13/50 [00:25<01:22,  2.23s/it]
..28%|████████████                               | 14/50 [00:28<01:21,  2.25s/it]
..30%|████████████▉                              | 15/50 [00:29<01:15,  2.16s/it]
...32%|█████████████▊                             | 16/50 [00:31<01:09,  2.06s/it]
..34%|██████████████▌                            | 17/50 [00:34<01:11,  2.18s/it]
..36%|███████████████▍                           | 18/50 [00:36<01:07,  2.12s/it]
..38%|████████████████▎                          | 19/50 [00:38<01:07,  2.19s/it]
..40%|█████████████████▏                         | 20/50 [00:40<01:05,  2.18s/it]
..42%|██████████████████                         | 21/50 [00:43<01:04,  2.22s/it]
..44%|██████████████████▉                        | 22/50 [00:45<01:00,  2.16s/it]
...46%|███████████████████▊                       | 23/50 [00:46<00:55,  2.06s/it]
..48%|████████████████████▋                      | 24/50 [00:49<00:56,  2.17s/it]
.50%|█████████████████████▌                     | 25/50 [00:51<00:52,  2.09s/it]
..52%|██████████████████████▎                    | 26/50 [00:53<00:48,  2.03s/it]
..54%|███████████████████████▏                   | 27/50 [00:54<00:45,  1.96s/it]
...56%|████████████████████████                   | 28/50 [00:56<00:43,  1.97s/it]
..58%|████████████████████████▉                  | 29/50 [00:59<00:47,  2.28s/it]
..60%|█████████████████████████▊                 | 30/50 [01:01<00:41,  2.10s/it]
...62%|██████████████████████████▋                | 31/50 [01:03<00:40,  2.13s/it]
..64%|███████████████████████████▌               | 32/50 [01:06<00:40,  2.25s/it]
..66%|████████████████████████████▍              | 33/50 [01:08<00:37,  2.22s/it]
...68%|█████████████████████████████▏             | 34/50 [01:10<00:36,  2.27s/it]
..70%|██████████████████████████████             | 35/50 [01:13<00:37,  2.47s/it]
...72%|██████████████████████████████▉            | 36/50 [01:15<00:33,  2.36s/it]
.74%|███████████████████████████████▊           | 37/50 [01:18<00:31,  2.40s/it]
...76%|████████████████████████████████▋          | 38/50 [01:20<00:26,  2.17s/it]
..78%|█████████████████████████████████▌         | 39/50 [01:22<00:24,  2.21s/it]
..80%|██████████████████████████████████▍        | 40/50 [01:24<00:21,  2.11s/it]
..82%|███████████████████████████████████▎       | 41/50 [01:26<00:19,  2.14s/it]
..84%|████████████████████████████████████       | 42/50 [01:28<00:17,  2.20s/it]
..86%|████████████████████████████████████▉      | 43/50 [01:30<00:14,  2.06s/it]
..88%|█████████████████████████████████████▊     | 44/50 [01:32<00:12,  2.12s/it]
..90%|██████████████████████████████████████▋    | 45/50 [01:34<00:10,  2.03s/it]
...92%|███████████████████████████████████████▌   | 46/50 [01:36<00:08,  2.09s/it]
..94%|████████████████████████████████████████▍  | 47/50 [01:39<00:06,  2.20s/it]
..96%|█████████████████████████████████████████▎ | 48/50 [01:41<00:04,  2.25s/it]
..98%|██████████████████████████████████████████▏| 49/50 [01:43<00:02,  2.20s/it]
100%|███████████████████████████████████████████| 50/50 [01:45<00:00,  1.99s/it]
compute_metrics ...
Current timestamp: 2024-06-20 21:11:44

running: tokenizer.batch_decode(pred_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:11:44
............................................................................
running: label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:13:00
..........................................................................
running: wer = 100 * metric.compute(predictions=pred_str, references=label_str)...
Current timestamp: 2024-06-20 21:14:15
.
{'eval_loss': 0.24474425613880157, 'eval_wer': 80.76923076923077, 'eval_runtime': 258.8123, 'eval_samples_per_second': 0.386, 'eval_steps_per_second': 0.193, 'epoch': 5.12}
20%|████████▍                                 | 32/160 [15:59<27:09, 12.73s/it]
100%|███████████████████████████████████████████| 50/50 [04:16<00:00,  1.99s/it]
Checkpoint destination directory /mnt/remote/models/whisper/whisper-large-v3-yue/checkpoint-32 already exists and is non-empty.Saving will proceed but saved results may be invalid.
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'begin_suppress_tokens': [220, 50256]}
{'loss': 0.0061, 'learning_rate': 7.77777777777778e-06, 'epoch': 7.68}
...30%|████████████▌                             | 48/160 [19:57<23:48, 12.75s/it]
..0%|                                                    | 0/50 [00:00<?, ?it/s]
..4%|█▊                                          | 2/50 [00:02<00:48,  1.01s/it]
...6%|██▋                                         | 3/50 [00:04<01:11,  1.53s/it]
..8%|███▌                                        | 4/50 [00:06<01:27,  1.90s/it]
..10%|████▍                                       | 5/50 [00:08<01:27,  1.93s/it]
..12%|█████▎                                      | 6/50 [00:10<01:24,  1.92s/it]
.14%|██████▏                                     | 7/50 [00:12<01:23,  1.94s/it]
...16%|███████                                     | 8/50 [00:14<01:21,  1.93s/it]
...18%|███████▉                                    | 9/50 [00:17<01:32,  2.26s/it]
..20%|████████▌                                  | 10/50 [00:20<01:33,  2.35s/it]
..22%|█████████▍                                 | 11/50 [00:21<01:24,  2.16s/it]
..24%|██████████▎                                | 12/50 [00:23<01:21,  2.16s/it]
...26%|███████████▏                               | 13/50 [00:26<01:21,  2.19s/it]
.28%|████████████                               | 14/50 [00:28<01:21,  2.25s/it]
..30%|████████████▉                              | 15/50 [00:30<01:13,  2.10s/it]
...32%|█████████████▊                             | 16/50 [00:32<01:09,  2.03s/it]
..34%|██████████████▌                            | 17/50 [00:34<01:13,  2.22s/it]
..36%|███████████████▍                           | 18/50 [00:36<01:08,  2.14s/it]
..38%|████████████████▎                          | 19/50 [00:39<01:08,  2.20s/it]
...40%|█████████████████▏                         | 20/50 [00:41<01:05,  2.19s/it]
..42%|██████████████████                         | 21/50 [00:43<01:04,  2.21s/it]
.44%|██████████████████▉                        | 22/50 [00:45<01:00,  2.17s/it]
...46%|███████████████████▊                       | 23/50 [00:47<00:54,  2.03s/it]
..48%|████████████████████▋                      | 24/50 [00:49<00:56,  2.17s/it]
..50%|█████████████████████▌                     | 25/50 [00:51<00:52,  2.09s/it]
..52%|██████████████████████▎                    | 26/50 [00:53<00:49,  2.06s/it]
..54%|███████████████████████▏                   | 27/50 [00:55<00:45,  2.00s/it]
..56%|████████████████████████                   | 28/50 [00:57<00:44,  2.02s/it]
..58%|████████████████████████▉                  | 29/50 [01:00<00:47,  2.27s/it]
..60%|█████████████████████████▊                 | 30/50 [01:02<00:42,  2.11s/it]
...62%|██████████████████████████▋                | 31/50 [01:04<00:40,  2.14s/it]
..64%|███████████████████████████▌               | 32/50 [01:06<00:39,  2.22s/it]
..66%|████████████████████████████▍              | 33/50 [01:09<00:37,  2.20s/it]
...68%|█████████████████████████████▏             | 34/50 [01:11<00:34,  2.19s/it]
..70%|██████████████████████████████             | 35/50 [01:14<00:36,  2.41s/it]
...72%|██████████████████████████████▉            | 36/50 [01:16<00:32,  2.31s/it]
.74%|███████████████████████████████▊           | 37/50 [01:18<00:30,  2.36s/it]
..76%|████████████████████████████████▋          | 38/50 [01:20<00:25,  2.14s/it]
..78%|█████████████████████████████████▌         | 39/50 [01:22<00:23,  2.18s/it]
..80%|██████████████████████████████████▍        | 40/50 [01:24<00:20,  2.08s/it]
...82%|███████████████████████████████████▎       | 41/50 [01:26<00:18,  2.02s/it]
..84%|████████████████████████████████████       | 42/50 [01:28<00:17,  2.18s/it]
..86%|████████████████████████████████████▉      | 43/50 [01:30<00:14,  2.13s/it]
..88%|█████████████████████████████████████▊     | 44/50 [01:33<00:12,  2.14s/it]
..90%|██████████████████████████████████████▋    | 45/50 [01:34<00:10,  2.06s/it]
..92%|███████████████████████████████████████▌   | 46/50 [01:37<00:08,  2.11s/it]
...94%|████████████████████████████████████████▍  | 47/50 [01:39<00:06,  2.20s/it]
..96%|█████████████████████████████████████████▎ | 48/50 [01:41<00:04,  2.25s/it]
.98%|██████████████████████████████████████████▏| 49/50 [01:44<00:02,  2.23s/it]
100%|███████████████████████████████████████████| 50/50 [01:45<00:00,  2.00s/it]
compute_metrics ...
Current timestamp: 2024-06-20 21:20:01

running: tokenizer.batch_decode(pred_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:20:01
...............................................................................
running: label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:21:20
............................................................................
running: wer = 100 * metric.compute(predictions=pred_str, references=label_str)...
Current timestamp: 2024-06-20 21:22:36

{'eval_loss': 0.25890761613845825, 'eval_wer': 82.6923076923077, 'eval_runtime': 263.1123, 'eval_samples_per_second': 0.38, 'eval_steps_per_second': 0.19, 'epoch': 7.68}
30%|████████████▌                             | 48/160 [24:20<23:48, 12.75s/it]
100%|███████████████████████████████████████████| 50/50 [04:20<00:00,  2.00s/it]
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'begin_suppress_tokens': [220, 50256]}
{'loss': 0.0025, 'learning_rate': 6.666666666666667e-06, 'epoch': 10.24}
...40%|████████████████▊                         | 64/160 [28:17<20:16, 12.67s/it]
..0%|                                                    | 0/50 [00:00<?, ?it/s]
..4%|█▊                                          | 2/50 [00:02<00:48,  1.01s/it]
...6%|██▋                                         | 3/50 [00:04<01:10,  1.51s/it]
..8%|███▌                                        | 4/50 [00:06<01:27,  1.91s/it]
.10%|████▍                                       | 5/50 [00:08<01:26,  1.92s/it]
..12%|█████▎                                      | 6/50 [00:10<01:22,  1.88s/it]
..14%|██████▏                                     | 7/50 [00:12<01:22,  1.93s/it]
...16%|███████                                     | 8/50 [00:14<01:20,  1.92s/it]
...18%|███████▉                                    | 9/50 [00:17<01:30,  2.21s/it]
..20%|████████▌                                  | 10/50 [00:19<01:33,  2.34s/it]
..22%|█████████▍                                 | 11/50 [00:21<01:24,  2.17s/it]
..24%|██████████▎                                | 12/50 [00:23<01:20,  2.12s/it]
..26%|███████████▏                               | 13/50 [00:26<01:22,  2.22s/it]
..28%|████████████                               | 14/50 [00:28<01:21,  2.27s/it]
..30%|████████████▉                              | 15/50 [00:30<01:13,  2.09s/it]
..32%|█████████████▊                             | 16/50 [00:32<01:08,  2.01s/it]
..34%|██████████████▌                            | 17/50 [00:34<01:11,  2.18s/it]
...36%|███████████████▍                           | 18/50 [00:36<01:07,  2.12s/it]
..38%|████████████████▎                          | 19/50 [00:39<01:07,  2.19s/it]
..40%|█████████████████▏                         | 20/50 [00:41<01:05,  2.20s/it]
..42%|██████████████████                         | 21/50 [00:43<01:06,  2.28s/it]
..44%|██████████████████▉                        | 22/50 [00:45<01:01,  2.20s/it]
...46%|███████████████████▊                       | 23/50 [00:47<00:55,  2.05s/it]
..48%|████████████████████▋                      | 24/50 [00:49<00:57,  2.20s/it]
..50%|█████████████████████▌                     | 25/50 [00:51<00:52,  2.11s/it]
.52%|██████████████████████▎                    | 26/50 [00:53<00:49,  2.07s/it]
..54%|███████████████████████▏                   | 27/50 [00:55<00:45,  2.00s/it]
....56%|████████████████████████                   | 28/50 [00:57<00:44,  2.00s/it]
.58%|████████████████████████▉                  | 29/50 [01:00<00:49,  2.36s/it]
...60%|█████████████████████████▊                 | 30/50 [01:02<00:42,  2.15s/it]
..62%|██████████████████████████▋                | 31/50 [01:04<00:42,  2.22s/it]
..64%|███████████████████████████▌               | 32/50 [01:07<00:40,  2.27s/it]
...66%|████████████████████████████▍              | 33/50 [01:09<00:38,  2.25s/it]
...68%|█████████████████████████████▏             | 34/50 [01:11<00:36,  2.27s/it]
..70%|██████████████████████████████             | 35/50 [01:14<00:37,  2.50s/it]
..72%|██████████████████████████████▉            | 36/50 [01:16<00:33,  2.39s/it]
..74%|███████████████████████████████▊           | 37/50 [01:19<00:31,  2.39s/it]
..76%|████████████████████████████████▋          | 38/50 [01:21<00:26,  2.18s/it]
..78%|█████████████████████████████████▌         | 39/50 [01:23<00:24,  2.20s/it]
..80%|██████████████████████████████████▍        | 40/50 [01:25<00:21,  2.10s/it]
..82%|███████████████████████████████████▎       | 41/50 [01:27<00:19,  2.12s/it]
..84%|████████████████████████████████████       | 42/50 [01:29<00:17,  2.20s/it]
...86%|████████████████████████████████████▉      | 43/50 [01:31<00:14,  2.11s/it]
..88%|█████████████████████████████████████▊     | 44/50 [01:33<00:12,  2.16s/it]
..90%|██████████████████████████████████████▋    | 45/50 [01:35<00:10,  2.08s/it]
..92%|███████████████████████████████████████▌   | 46/50 [01:38<00:08,  2.12s/it]
...94%|████████████████████████████████████████▍  | 47/50 [01:40<00:06,  2.19s/it]
..96%|█████████████████████████████████████████▎ | 48/50 [01:42<00:04,  2.27s/it]
.98%|██████████████████████████████████████████▏| 49/50 [01:45<00:02,  2.25s/it]
100%|███████████████████████████████████████████| 50/50 [01:46<00:00,  2.04s/it]
compute_metrics ...
Current timestamp: 2024-06-20 21:28:22

running: tokenizer.batch_decode(pred_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:28:22
.................................................................................
running: label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:29:43
............................................................................
running: wer = 100 * metric.compute(predictions=pred_str, references=label_str)...
Current timestamp: 2024-06-20 21:30:59

{'eval_loss': 0.2861306667327881, 'eval_wer': 78.84615384615384, 'eval_runtime': 265.7853, 'eval_samples_per_second': 0.376, 'eval_steps_per_second': 0.188, 'epoch': 10.24}
40%|████████████████▊                         | 64/160 [32:43<20:16, 12.67s/it]
100%|███████████████████████████████████████████| 50/50 [04:23<00:00,  2.04s/it]
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'begin_suppress_tokens': [220, 50256]}
{'loss': 0.0005, 'learning_rate': 5.555555555555557e-06, 'epoch': 12.8}
..50%|█████████████████████                     | 80/160 [36:28<16:54, 12.69s/it]
..0%|                                                    | 0/50 [00:00<?, ?it/s]
...4%|█▊                                          | 2/50 [00:02<00:49,  1.02s/it]
..6%|██▋                                         | 3/50 [00:04<01:10,  1.50s/it]
..8%|███▌                                        | 4/50 [00:06<01:27,  1.91s/it]
..10%|████▍                                       | 5/50 [00:08<01:25,  1.91s/it]
..12%|█████▎                                      | 6/50 [00:10<01:22,  1.87s/it]
..14%|██████▏                                     | 7/50 [00:12<01:20,  1.88s/it]
...16%|███████                                     | 8/50 [00:14<01:19,  1.90s/it]
..18%|███████▉                                    | 9/50 [00:17<01:30,  2.21s/it]
..20%|████████▌                                  | 10/50 [00:19<01:32,  2.31s/it]
..22%|█████████▍                                 | 11/50 [00:21<01:24,  2.16s/it]
..24%|██████████▎                                | 12/50 [00:23<01:21,  2.14s/it]
...26%|███████████▏                               | 13/50 [00:26<01:21,  2.21s/it]
..28%|████████████                               | 14/50 [00:28<01:21,  2.27s/it]
.30%|████████████▉                              | 15/50 [00:30<01:13,  2.10s/it]
...32%|█████████████▊                             | 16/50 [00:32<01:09,  2.03s/it]
..34%|██████████████▌                            | 17/50 [00:34<01:13,  2.23s/it]
..36%|███████████████▍                           | 18/50 [00:36<01:08,  2.15s/it]
...38%|████████████████▎                          | 19/50 [00:39<01:09,  2.23s/it]
..40%|█████████████████▏                         | 20/50 [00:41<01:06,  2.23s/it]
..42%|██████████████████                         | 21/50 [00:43<01:06,  2.30s/it]
..44%|██████████████████▉                        | 22/50 [00:45<01:01,  2.21s/it]
..46%|███████████████████▊                       | 23/50 [00:47<00:55,  2.06s/it]
..48%|████████████████████▋                      | 24/50 [00:50<00:56,  2.19s/it]
..50%|█████████████████████▌                     | 25/50 [00:51<00:52,  2.11s/it]
..52%|██████████████████████▎                    | 26/50 [00:53<00:49,  2.07s/it]
..54%|███████████████████████▏                   | 27/50 [00:55<00:46,  2.01s/it]
...56%|████████████████████████                   | 28/50 [00:57<00:44,  2.02s/it]
..58%|████████████████████████▉                  | 29/50 [01:00<00:48,  2.31s/it]
..60%|█████████████████████████▊                 | 30/50 [01:02<00:42,  2.12s/it]
...62%|██████████████████████████▋                | 31/50 [01:04<00:41,  2.20s/it]
..64%|███████████████████████████▌               | 32/50 [01:07<00:40,  2.27s/it]
..66%|████████████████████████████▍              | 33/50 [01:09<00:38,  2.26s/it]
...68%|█████████████████████████████▏             | 34/50 [01:11<00:36,  2.29s/it]
..70%|██████████████████████████████             | 35/50 [01:14<00:37,  2.50s/it]
...72%|██████████████████████████████▉            | 36/50 [01:17<00:33,  2.39s/it]
.74%|███████████████████████████████▊           | 37/50 [01:19<00:31,  2.39s/it]
...76%|████████████████████████████████▋          | 38/50 [01:21<00:25,  2.16s/it]
..78%|█████████████████████████████████▌         | 39/50 [01:23<00:24,  2.22s/it]
..80%|██████████████████████████████████▍        | 40/50 [01:25<00:21,  2.12s/it]
..82%|███████████████████████████████████▎       | 41/50 [01:27<00:19,  2.13s/it]
..84%|████████████████████████████████████       | 42/50 [01:29<00:17,  2.21s/it]
...86%|████████████████████████████████████▉      | 43/50 [01:31<00:15,  2.17s/it]
.88%|█████████████████████████████████████▊     | 44/50 [01:34<00:13,  2.21s/it]
...90%|██████████████████████████████████████▋    | 45/50 [01:36<00:10,  2.11s/it]
..92%|███████████████████████████████████████▌   | 46/50 [01:38<00:08,  2.14s/it]
..94%|████████████████████████████████████████▍  | 47/50 [01:40<00:06,  2.20s/it]
...96%|█████████████████████████████████████████▎ | 48/50 [01:43<00:04,  2.26s/it]
.98%|██████████████████████████████████████████▏| 49/50 [01:45<00:02,  2.24s/it]
100%|███████████████████████████████████████████| 50/50 [01:46<00:00,  2.04s/it]
compute_metrics ...
Current timestamp: 2024-06-20 21:36:33

running: tokenizer.batch_decode(pred_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:36:33
..................................................................................
running: label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:37:55
............................................................................
running: wer = 100 * metric.compute(predictions=pred_str, references=label_str)...
Current timestamp: 2024-06-20 21:39:11

{'eval_loss': 0.28269854187965393, 'eval_wer': 75.0, 'eval_runtime': 267.5295, 'eval_samples_per_second': 0.374, 'eval_steps_per_second': 0.187, 'epoch': 12.8}
50%|█████████████████████                     | 80/160 [40:56<16:54, 12.69s/it]
100%|███████████████████████████████████████████| 50/50 [04:24<00:00,  2.04s/it]
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'begin_suppress_tokens': [220, 50256]}
{'loss': 0.0003, 'learning_rate': 4.444444444444444e-06, 'epoch': 15.36}
...60%|█████████████████████████▏                | 96/160 [44:39<13:29, 12.65s/it]
..0%|                                                    | 0/50 [00:00<?, ?it/s]
..4%|█▊                                          | 2/50 [00:01<00:47,  1.01it/s]
...6%|██▋                                         | 3/50 [00:04<01:10,  1.50s/it]
.8%|███▌                                        | 4/50 [00:06<01:27,  1.91s/it]
..10%|████▍                                       | 5/50 [00:08<01:25,  1.90s/it]
..12%|█████▎                                      | 6/50 [00:10<01:21,  1.85s/it]
..14%|██████▏                                     | 7/50 [00:12<01:22,  1.92s/it]
...16%|███████                                     | 8/50 [00:14<01:20,  1.92s/it]
...18%|███████▉                                    | 9/50 [00:17<01:31,  2.22s/it]
.20%|████████▌                                  | 10/50 [00:19<01:33,  2.33s/it]
..22%|█████████▍                                 | 11/50 [00:21<01:25,  2.18s/it]
...24%|██████████▎                                | 12/50 [00:23<01:20,  2.12s/it]
..26%|███████████▏                               | 13/50 [00:26<01:21,  2.20s/it]
..28%|████████████                               | 14/50 [00:28<01:21,  2.25s/it]
..30%|████████████▉                              | 15/50 [00:30<01:12,  2.08s/it]
..32%|█████████████▊                             | 16/50 [00:31<01:08,  2.01s/it]
..34%|██████████████▌                            | 17/50 [00:34<01:13,  2.22s/it]
...36%|███████████████▍                           | 18/50 [00:36<01:08,  2.14s/it]
..38%|████████████████▎                          | 19/50 [00:38<01:08,  2.20s/it]
..40%|█████████████████▏                         | 20/50 [00:41<01:05,  2.19s/it]
..42%|██████████████████                         | 21/50 [00:43<01:05,  2.26s/it]
..44%|██████████████████▉                        | 22/50 [00:45<01:01,  2.20s/it]
...46%|███████████████████▊                       | 23/50 [00:47<00:55,  2.06s/it]
..48%|████████████████████▋                      | 24/50 [00:49<00:57,  2.20s/it]
..50%|█████████████████████▌                     | 25/50 [00:51<00:53,  2.13s/it]
.52%|██████████████████████▎                    | 26/50 [00:53<00:49,  2.08s/it]
..54%|███████████████████████▏                   | 27/50 [00:55<00:46,  2.00s/it]
...56%|████████████████████████                   | 28/50 [00:57<00:44,  2.04s/it]
..58%|████████████████████████▉                  | 29/50 [01:00<00:48,  2.29s/it]
..60%|█████████████████████████▊                 | 30/50 [01:02<00:42,  2.11s/it]
...62%|██████████████████████████▋                | 31/50 [01:04<00:42,  2.22s/it]
..64%|███████████████████████████▌               | 32/50 [01:07<00:40,  2.27s/it]
..66%|████████████████████████████▍              | 33/50 [01:09<00:38,  2.25s/it]
...68%|█████████████████████████████▏             | 34/50 [01:11<00:36,  2.28s/it]
..70%|██████████████████████████████             | 35/50 [01:14<00:37,  2.49s/it]
...72%|██████████████████████████████▉            | 36/50 [01:16<00:33,  2.37s/it]
..74%|███████████████████████████████▊           | 37/50 [01:19<00:31,  2.39s/it]
..76%|████████████████████████████████▋          | 38/50 [01:20<00:25,  2.17s/it]
.78%|█████████████████████████████████▌         | 39/50 [01:22<00:23,  2.11s/it]
...80%|██████████████████████████████████▍        | 40/50 [01:24<00:20,  2.05s/it]
..82%|███████████████████████████████████▎       | 41/50 [01:26<00:18,  2.08s/it]
..84%|████████████████████████████████████       | 42/50 [01:29<00:17,  2.17s/it]
..86%|████████████████████████████████████▉      | 43/50 [01:31<00:15,  2.19s/it]
..88%|█████████████████████████████████████▊     | 44/50 [01:33<00:13,  2.20s/it]
...90%|██████████████████████████████████████▋    | 45/50 [01:35<00:10,  2.10s/it]
..92%|███████████████████████████████████████▌   | 46/50 [01:37<00:08,  2.15s/it]
..94%|████████████████████████████████████████▍  | 47/50 [01:40<00:06,  2.20s/it]
...96%|█████████████████████████████████████████▎ | 48/50 [01:42<00:04,  2.26s/it]
.98%|██████████████████████████████████████████▏| 49/50 [01:44<00:02,  2.25s/it]
100%|███████████████████████████████████████████| 50/50 [01:46<00:00,  2.08s/it]
compute_metrics ...
Current timestamp: 2024-06-20 21:44:43

running: tokenizer.batch_decode(pred_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:44:43
....................................................................................
running: label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:46:07
...................................................................................
running: wer = 100 * metric.compute(predictions=pred_str, references=label_str)...
Current timestamp: 2024-06-20 21:47:31

{'eval_loss': 0.28264206647872925, 'eval_wer': 74.03846153846155, 'eval_runtime': 276.2251, 'eval_samples_per_second': 0.362, 'eval_steps_per_second': 0.181, 'epoch': 15.36}
60%|█████████████████████████▏                | 96/160 [49:15<13:29, 12.65s/it]
100%|███████████████████████████████████████████| 50/50 [04:33<00:00,  2.08s/it]
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'begin_suppress_tokens': [220, 50256]}
{'loss': 0.0003, 'learning_rate': 3.3333333333333333e-06, 'epoch': 17.92}
...70%|████████████████████████████▋            | 112/160 [52:59<10:07, 12.66s/it]
..0%|                                                    | 0/50 [00:00<?, ?it/s]
..4%|█▊                                          | 2/50 [00:02<00:48,  1.00s/it]
...6%|██▋                                         | 3/50 [00:04<01:09,  1.48s/it]
.8%|███▌                                        | 4/50 [00:06<01:26,  1.89s/it]
..10%|████▍                                       | 5/50 [00:08<01:26,  1.92s/it]
..12%|█████▎                                      | 6/50 [00:10<01:23,  1.90s/it]
..14%|██████▏                                     | 7/50 [00:12<01:23,  1.94s/it]
...16%|███████                                     | 8/50 [00:14<01:20,  1.93s/it]
...18%|███████▉                                    | 9/50 [00:17<01:30,  2.21s/it]
..20%|████████▌                                  | 10/50 [00:19<01:33,  2.34s/it]
..22%|█████████▍                                 | 11/50 [00:21<01:24,  2.17s/it]
..24%|██████████▎                                | 12/50 [00:23<01:20,  2.12s/it]
..26%|███████████▏                               | 13/50 [00:26<01:21,  2.19s/it]
..28%|████████████                               | 14/50 [00:28<01:21,  2.26s/it]
..30%|████████████▉                              | 15/50 [00:30<01:12,  2.08s/it]
..32%|█████████████▊                             | 16/50 [00:31<01:07,  2.00s/it]
..34%|██████████████▌                            | 17/50 [00:34<01:13,  2.22s/it]
...36%|███████████████▍                           | 18/50 [00:36<01:08,  2.14s/it]
..38%|████████████████▎                          | 19/50 [00:39<01:08,  2.20s/it]
..40%|█████████████████▏                         | 20/50 [00:41<01:05,  2.20s/it]
..42%|██████████████████                         | 21/50 [00:43<01:05,  2.26s/it]
..44%|██████████████████▉                        | 22/50 [00:45<01:01,  2.20s/it]
...46%|███████████████████▊                       | 23/50 [00:47<00:55,  2.04s/it]
..48%|████████████████████▋                      | 24/50 [00:49<00:56,  2.19s/it]
..50%|█████████████████████▌                     | 25/50 [00:51<00:52,  2.11s/it]
.52%|██████████████████████▎                    | 26/50 [00:53<00:49,  2.06s/it]
..54%|███████████████████████▏                   | 27/50 [00:55<00:46,  2.00s/it]
....56%|████████████████████████                   | 28/50 [00:57<00:44,  2.02s/it]
.58%|████████████████████████▉                  | 29/50 [01:00<00:49,  2.34s/it]
...60%|█████████████████████████▊                 | 30/50 [01:02<00:42,  2.15s/it]
..62%|██████████████████████████▋                | 31/50 [01:04<00:42,  2.22s/it]
..64%|███████████████████████████▌               | 32/50 [01:07<00:40,  2.28s/it]
...66%|████████████████████████████▍              | 33/50 [01:09<00:38,  2.25s/it]
...68%|█████████████████████████████▏             | 34/50 [01:11<00:36,  2.27s/it]
..70%|██████████████████████████████             | 35/50 [01:14<00:37,  2.53s/it]
..72%|██████████████████████████████▉            | 36/50 [01:16<00:33,  2.39s/it]
..74%|███████████████████████████████▊           | 37/50 [01:19<00:31,  2.40s/it]
..76%|████████████████████████████████▋          | 38/50 [01:21<00:26,  2.17s/it]
..78%|█████████████████████████████████▌         | 39/50 [01:23<00:23,  2.13s/it]
..80%|██████████████████████████████████▍        | 40/50 [01:25<00:20,  2.09s/it]
..82%|███████████████████████████████████▎       | 41/50 [01:27<00:18,  2.10s/it]
..84%|████████████████████████████████████       | 42/50 [01:29<00:17,  2.18s/it]
...86%|████████████████████████████████████▉      | 43/50 [01:31<00:15,  2.18s/it]
..88%|█████████████████████████████████████▊     | 44/50 [01:34<00:13,  2.22s/it]
..90%|██████████████████████████████████████▋    | 45/50 [01:35<00:10,  2.10s/it]
..92%|███████████████████████████████████████▌   | 46/50 [01:38<00:08,  2.14s/it]
...94%|████████████████████████████████████████▍  | 47/50 [01:40<00:06,  2.20s/it]
..96%|█████████████████████████████████████████▎ | 48/50 [01:42<00:04,  2.27s/it]
..98%|██████████████████████████████████████████▏| 49/50 [01:45<00:02,  2.28s/it]
100%|███████████████████████████████████████████| 50/50 [01:46<00:00,  2.08s/it]
compute_metrics ...
Current timestamp: 2024-06-20 21:53:04

running: tokenizer.batch_decode(pred_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:53:04
..............................................................................
running: label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 21:54:22
..........................................................................
running: wer = 100 * metric.compute(predictions=pred_str, references=label_str)...
Current timestamp: 2024-06-20 21:55:37

{'eval_loss': 0.2837233245372772, 'eval_wer': 72.11538461538461, 'eval_runtime': 262.0009, 'eval_samples_per_second': 0.382, 'eval_steps_per_second': 0.191, 'epoch': 17.92}
70%|████████████████████████████▋            | 112/160 [57:21<10:07, 12.66s/it]
100%|███████████████████████████████████████████| 50/50 [04:19<00:00,  2.08s/it]
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'begin_suppress_tokens': [220, 50256]}
{'loss': 0.0002, 'learning_rate': 2.222222222222222e-06, 'epoch': 20.48}
..80%|███████████████████████████████▏       | 128/160 [1:01:05<06:46, 12.70s/it]
..0%|                                                    | 0/50 [00:00<?, ?it/s]
..4%|█▊                                          | 2/50 [00:02<00:48,  1.01s/it]
...6%|██▋                                         | 3/50 [00:04<01:10,  1.50s/it]
..8%|███▌                                        | 4/50 [00:06<01:26,  1.89s/it]
..10%|████▍                                       | 5/50 [00:08<01:25,  1.89s/it]
..12%|█████▎                                      | 6/50 [00:10<01:23,  1.89s/it]
..14%|██████▏                                     | 7/50 [00:12<01:23,  1.93s/it]
...16%|███████                                     | 8/50 [00:14<01:20,  1.92s/it]
..18%|███████▉                                    | 9/50 [00:17<01:31,  2.23s/it]
..20%|████████▌                                  | 10/50 [00:20<01:35,  2.38s/it]
..22%|█████████▍                                 | 11/50 [00:21<01:25,  2.20s/it]
...24%|██████████▎                                | 12/50 [00:23<01:21,  2.15s/it]
..26%|███████████▏                               | 13/50 [00:26<01:23,  2.24s/it]
..28%|████████████                               | 14/50 [00:28<01:22,  2.29s/it]
..30%|████████████▉                              | 15/50 [00:30<01:13,  2.11s/it]
..32%|█████████████▊                             | 16/50 [00:32<01:08,  2.03s/it]
..34%|██████████████▌                            | 17/50 [00:35<01:14,  2.26s/it]
...36%|███████████████▍                           | 18/50 [00:37<01:09,  2.17s/it]
..38%|████████████████▎                          | 19/50 [00:39<01:09,  2.24s/it]
..40%|█████████████████▏                         | 20/50 [00:41<01:06,  2.21s/it]
..42%|██████████████████                         | 21/50 [00:44<01:05,  2.27s/it]
..44%|██████████████████▉                        | 22/50 [00:46<01:01,  2.19s/it]
...46%|███████████████████▊                       | 23/50 [00:47<00:56,  2.08s/it]
..48%|████████████████████▋                      | 24/50 [00:50<00:57,  2.23s/it]
.50%|█████████████████████▌                     | 25/50 [00:52<00:53,  2.13s/it]
..52%|██████████████████████▎                    | 26/50 [00:54<00:49,  2.07s/it]
..54%|███████████████████████▏                   | 27/50 [00:56<00:45,  2.00s/it]
...56%|████████████████████████                   | 28/50 [00:58<00:43,  1.99s/it]
..58%|████████████████████████▉                  | 29/50 [01:00<00:47,  2.27s/it]
..60%|█████████████████████████▊                 | 30/50 [01:02<00:41,  2.10s/it]
...62%|██████████████████████████▋                | 31/50 [01:05<00:41,  2.19s/it]
..64%|███████████████████████████▌               | 32/50 [01:07<00:40,  2.27s/it]
..66%|████████████████████████████▍              | 33/50 [01:09<00:37,  2.23s/it]
...68%|█████████████████████████████▏             | 34/50 [01:12<00:36,  2.28s/it]
..70%|██████████████████████████████             | 35/50 [01:15<00:37,  2.51s/it]
...72%|██████████████████████████████▉            | 36/50 [01:17<00:33,  2.38s/it]
.74%|███████████████████████████████▊           | 37/50 [01:19<00:31,  2.39s/it]
...76%|████████████████████████████████▋          | 38/50 [01:21<00:25,  2.16s/it]
..78%|█████████████████████████████████▌         | 39/50 [01:23<00:23,  2.14s/it]
..80%|██████████████████████████████████▍        | 40/50 [01:25<00:21,  2.10s/it]
..82%|███████████████████████████████████▎       | 41/50 [01:27<00:19,  2.13s/it]
..84%|████████████████████████████████████       | 42/50 [01:29<00:17,  2.23s/it]
...86%|████████████████████████████████████▉      | 43/50 [01:32<00:15,  2.21s/it]
.88%|█████████████████████████████████████▊     | 44/50 [01:34<00:13,  2.21s/it]
...90%|██████████████████████████████████████▋    | 45/50 [01:36<00:10,  2.09s/it]
..92%|███████████████████████████████████████▌   | 46/50 [01:38<00:08,  2.16s/it]
..94%|████████████████████████████████████████▍  | 47/50 [01:40<00:06,  2.23s/it]
...96%|█████████████████████████████████████████▎ | 48/50 [01:43<00:04,  2.26s/it]
.98%|██████████████████████████████████████████▏| 49/50 [01:45<00:02,  2.25s/it]
100%|███████████████████████████████████████████| 50/50 [01:47<00:00,  2.04s/it]
compute_metrics ...
Current timestamp: 2024-06-20 22:01:10

running: tokenizer.batch_decode(pred_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 22:01:10
............................................................................
running: label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 22:02:25
.........................................................................
running: wer = 100 * metric.compute(predictions=pred_str, references=label_str)...
Current timestamp: 2024-06-20 22:03:39

{'eval_loss': 0.28444424271583557, 'eval_wer': 72.11538461538461, 'eval_runtime': 258.9484, 'eval_samples_per_second': 0.386, 'eval_steps_per_second': 0.193, 'epoch': 20.48}
80%|███████████████████████████████▏       | 128/160 [1:05:24<06:46, 12.70s/it]
100%|███████████████████████████████████████████| 50/50 [04:16<00:00,  2.04s/it]
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'begin_suppress_tokens': [220, 50256]}
{'loss': 0.0002, 'learning_rate': 1.111111111111111e-06, 'epoch': 23.04}
...90%|███████████████████████████████████    | 144/160 [1:09:09<03:22, 12.63s/it]
..0%|                                                    | 0/50 [00:00<?, ?it/s]
..4%|█▊                                          | 2/50 [00:02<00:48,  1.01s/it]
..6%|██▋                                         | 3/50 [00:04<01:10,  1.50s/it]
..8%|███▌                                        | 4/50 [00:06<01:27,  1.89s/it]
..10%|████▍                                       | 5/50 [00:08<01:25,  1.89s/it]
..12%|█████▎                                      | 6/50 [00:10<01:22,  1.87s/it]
..14%|██████▏                                     | 7/50 [00:12<01:22,  1.92s/it]
...16%|███████                                     | 8/50 [00:14<01:20,  1.92s/it]
..18%|███████▉                                    | 9/50 [00:17<01:30,  2.21s/it]
..20%|████████▌                                  | 10/50 [00:19<01:33,  2.33s/it]
..22%|█████████▍                                 | 11/50 [00:21<01:24,  2.16s/it]
...24%|██████████▎                                | 12/50 [00:23<01:20,  2.12s/it]
..26%|███████████▏                               | 13/50 [00:26<01:21,  2.21s/it]
..28%|████████████                               | 14/50 [00:28<01:21,  2.26s/it]
..30%|████████████▉                              | 15/50 [00:30<01:13,  2.09s/it]
..32%|█████████████▊                             | 16/50 [00:32<01:08,  2.02s/it]
..34%|██████████████▌                            | 17/50 [00:34<01:12,  2.20s/it]
..36%|███████████████▍                           | 18/50 [00:36<01:08,  2.13s/it]
...38%|████████████████▎                          | 19/50 [00:38<01:08,  2.20s/it]
..40%|█████████████████▏                         | 20/50 [00:41<01:05,  2.19s/it]
..42%|██████████████████                         | 21/50 [00:43<01:05,  2.27s/it]
..44%|██████████████████▉                        | 22/50 [00:45<01:01,  2.20s/it]
..46%|███████████████████▊                       | 23/50 [00:47<00:56,  2.09s/it]
..48%|████████████████████▋                      | 24/50 [00:49<00:57,  2.22s/it]
..50%|█████████████████████▌                     | 25/50 [00:51<00:53,  2.13s/it]
..52%|██████████████████████▎                    | 26/50 [00:53<00:49,  2.08s/it]
..54%|███████████████████████▏                   | 27/50 [00:55<00:46,  2.01s/it]
...56%|████████████████████████                   | 28/50 [00:57<00:44,  2.00s/it]
..58%|████████████████████████▉                  | 29/50 [01:00<00:48,  2.30s/it]
..60%|█████████████████████████▊                 | 30/50 [01:02<00:42,  2.11s/it]
...62%|██████████████████████████▋                | 31/50 [01:04<00:41,  2.19s/it]
..64%|███████████████████████████▌               | 32/50 [01:07<00:40,  2.25s/it]
..66%|████████████████████████████▍              | 33/50 [01:09<00:38,  2.25s/it]
...68%|█████████████████████████████▏             | 34/50 [01:11<00:36,  2.31s/it]
..70%|██████████████████████████████             | 35/50 [01:14<00:37,  2.51s/it]
...72%|██████████████████████████████▉            | 36/50 [01:16<00:33,  2.37s/it]
.74%|███████████████████████████████▊           | 37/50 [01:19<00:31,  2.39s/it]
..76%|████████████████████████████████▋          | 38/50 [01:20<00:25,  2.16s/it]
..78%|█████████████████████████████████▌         | 39/50 [01:22<00:23,  2.13s/it]
...80%|██████████████████████████████████▍        | 40/50 [01:25<00:21,  2.10s/it]
..82%|███████████████████████████████████▎       | 41/50 [01:27<00:18,  2.11s/it]
..84%|████████████████████████████████████       | 42/50 [01:29<00:17,  2.21s/it]
..86%|████████████████████████████████████▉      | 43/50 [01:31<00:15,  2.20s/it]
..88%|█████████████████████████████████████▊     | 44/50 [01:34<00:13,  2.21s/it]
...90%|██████████████████████████████████████▋    | 45/50 [01:35<00:10,  2.10s/it]
..92%|███████████████████████████████████████▌   | 46/50 [01:38<00:08,  2.17s/it]
..94%|████████████████████████████████████████▍  | 47/50 [01:40<00:06,  2.25s/it]
...96%|█████████████████████████████████████████▎ | 48/50 [01:43<00:04,  2.29s/it]
.98%|██████████████████████████████████████████▏| 49/50 [01:45<00:02,  2.28s/it]
100%|███████████████████████████████████████████| 50/50 [01:46<00:00,  2.06s/it]
compute_metrics ...
Current timestamp: 2024-06-20 22:09:14

running: tokenizer.batch_decode(pred_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 22:09:14
..................................................................................
running: label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 22:10:36
................................................................................
running: wer = 100 * metric.compute(predictions=pred_str, references=label_str)...
Current timestamp: 2024-06-20 22:11:56

{'eval_loss': 0.2848002314567566, 'eval_wer': 72.11538461538461, 'eval_runtime': 271.5821, 'eval_samples_per_second': 0.368, 'eval_steps_per_second': 0.184, 'epoch': 23.04}
90%|███████████████████████████████████    | 144/160 [1:13:41<03:22, 12.63s/it]
100%|███████████████████████████████████████████| 50/50 [04:28<00:00,  2.06s/it]
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'begin_suppress_tokens': [220, 50256]}
{'loss': 0.0002, 'learning_rate': 0.0, 'epoch': 25.6}
..100%|███████████████████████████████████████| 160/160 [1:17:24<00:00, 12.63s/it]
..0%|                                                    | 0/50 [00:00<?, ?it/s]
...4%|█▊                                          | 2/50 [00:01<00:47,  1.01it/s]
..6%|██▋                                         | 3/50 [00:04<01:08,  1.46s/it]
..8%|███▌                                        | 4/50 [00:06<01:26,  1.87s/it]
..10%|████▍                                       | 5/50 [00:08<01:24,  1.88s/it]
..12%|█████▎                                      | 6/50 [00:10<01:22,  1.88s/it]
..14%|██████▏                                     | 7/50 [00:12<01:23,  1.95s/it]
...16%|███████                                     | 8/50 [00:14<01:20,  1.93s/it]
..18%|███████▉                                    | 9/50 [00:17<01:31,  2.24s/it]
..20%|████████▌                                  | 10/50 [00:19<01:33,  2.34s/it]
..22%|█████████▍                                 | 11/50 [00:21<01:24,  2.18s/it]
...24%|██████████▎                                | 12/50 [00:23<01:20,  2.12s/it]
..26%|███████████▏                               | 13/50 [00:26<01:21,  2.22s/it]
..28%|████████████                               | 14/50 [00:28<01:21,  2.27s/it]
..30%|████████████▉                              | 15/50 [00:30<01:13,  2.10s/it]
..32%|█████████████▊                             | 16/50 [00:32<01:09,  2.03s/it]
..34%|██████████████▌                            | 17/50 [00:34<01:13,  2.22s/it]
..36%|███████████████▍                           | 18/50 [00:36<01:08,  2.13s/it]
...38%|████████████████▎                          | 19/50 [00:39<01:08,  2.20s/it]
..40%|█████████████████▏                         | 20/50 [00:41<01:05,  2.19s/it]
..42%|██████████████████                         | 21/50 [00:43<01:05,  2.27s/it]
..44%|██████████████████▉                        | 22/50 [00:45<01:01,  2.19s/it]
..46%|███████████████████▊                       | 23/50 [00:47<00:56,  2.08s/it]
..48%|████████████████████▋                      | 24/50 [00:49<00:57,  2.20s/it]
..50%|█████████████████████▌                     | 25/50 [00:51<00:52,  2.11s/it]
..52%|██████████████████████▎                    | 26/50 [00:53<00:49,  2.06s/it]
..54%|███████████████████████▏                   | 27/50 [00:55<00:45,  2.00s/it]
...56%|████████████████████████                   | 28/50 [00:57<00:44,  2.00s/it]
..58%|████████████████████████▉                  | 29/50 [01:00<00:48,  2.30s/it]
..60%|█████████████████████████▊                 | 30/50 [01:02<00:42,  2.11s/it]
..62%|██████████████████████████▋                | 31/50 [01:04<00:41,  2.20s/it]
...64%|███████████████████████████▌               | 32/50 [01:07<00:40,  2.24s/it]
..66%|████████████████████████████▍              | 33/50 [01:09<00:37,  2.22s/it]
...68%|█████████████████████████████▏             | 34/50 [01:11<00:36,  2.26s/it]
..70%|██████████████████████████████             | 35/50 [01:14<00:37,  2.51s/it]
...72%|██████████████████████████████▉            | 36/50 [01:16<00:33,  2.38s/it]
.74%|███████████████████████████████▊           | 37/50 [01:19<00:31,  2.39s/it]
..76%|████████████████████████████████▋          | 38/50 [01:20<00:26,  2.17s/it]
..78%|█████████████████████████████████▌         | 39/50 [01:22<00:23,  2.14s/it]
..80%|██████████████████████████████████▍        | 40/50 [01:24<00:21,  2.10s/it]
...82%|███████████████████████████████████▎       | 41/50 [01:27<00:19,  2.12s/it]
..84%|████████████████████████████████████       | 42/50 [01:29<00:17,  2.18s/it]
..86%|████████████████████████████████████▉      | 43/50 [01:31<00:15,  2.19s/it]
..88%|█████████████████████████████████████▊     | 44/50 [01:33<00:13,  2.21s/it]
..90%|██████████████████████████████████████▋    | 45/50 [01:35<00:10,  2.10s/it]
...92%|███████████████████████████████████████▌   | 46/50 [01:37<00:08,  2.14s/it]
..94%|████████████████████████████████████████▍  | 47/50 [01:40<00:06,  2.22s/it]
..96%|█████████████████████████████████████████▎ | 48/50 [01:42<00:04,  2.27s/it]
..98%|██████████████████████████████████████████▏| 49/50 [01:45<00:02,  2.27s/it]
100%|███████████████████████████████████████████| 50/50 [01:46<00:00,  2.06s/it]
compute_metrics ...
Current timestamp: 2024-06-20 22:17:29

running: tokenizer.batch_decode(pred_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 22:17:29
...............................................................................
running: label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)...
Current timestamp: 2024-06-20 22:18:49
.............................................................................
running: wer = 100 * metric.compute(predictions=pred_str, references=label_str)...
Current timestamp: 2024-06-20 22:20:05

{'eval_loss': 0.28493210673332214, 'eval_wer': 72.11538461538461, 'eval_runtime': 264.978, 'eval_samples_per_second': 0.377, 'eval_steps_per_second': 0.189, 'epoch': 25.6}
100%|███████████████████████████████████████| 160/160 [1:21:49<00:00, 12.63s/it]
100%|███████████████████████████████████████████| 50/50 [04:22<00:00,  2.06s/it]
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'begin_suppress_tokens': [220, 50256]}
...............................Could not locate the best model at /mnt/remote/models/whisper/whisper-large-v3-yue/checkpoint-112/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.
{'train_runtime': 4941.111, 'train_samples_per_second': 0.518, 'train_steps_per_second': 0.032, 'train_loss': 0.23526998192101017, 'epoch': 25.6}
100%|███████████████████████████████████████| 160/160 [1:22:21<00:00, 30.88s/it]
.......
 job done, program exist.

Process finished with exit code 0
