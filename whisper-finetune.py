#åœ¨å¾®è°ƒ Whisper æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬ä¼šç”¨åˆ°å‡ ä¸ªæµè¡Œçš„ Python åŒ…ã€‚æˆ‘ä»¬ä½¿ç”¨ datasets æ¥ä¸‹è½½å’Œå‡†å¤‡è®­ç»ƒæ•°æ®ï¼Œä½¿ç”¨ transformers æ¥åŠ è½½å’Œè®­ç»ƒ Whisper æ¨¡å‹ã€‚å¦å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ soundfile åŒ…æ¥é¢„å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼Œevaluate å’Œ jiwer æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚æœ€åï¼Œæˆ‘ä»¬ç”¨ gradio æ¥ä¸ºå¾®è°ƒåçš„æ¨¡å‹æ„å»ºä¸€ä¸ªäº®é—ªé—ªçš„æ¼”ç¤ºåº”ç”¨ã€‚

!pip install datasets>=2.6.1
!pip install git+https://github.com/huggingface/transformers
!pip install librosa
!pip install evaluate>=0.30
!pip install jiwer
!pip install gradio

#ä½¿ç”¨ ğŸ¤— Datasets æ¥ä¸‹è½½å’Œå‡†å¤‡æ•°æ®éå¸¸ç®€å•ã€‚ä»…éœ€ä¸€è¡Œä»£ç å³å¯å®Œæˆ Common Voice æ•°æ®é›†çš„ä¸‹è½½å’Œå‡†å¤‡å·¥ä½œã€‚ç”±äºå°åœ°è¯­æ•°æ®éå¸¸åŒ®ä¹ï¼Œæˆ‘ä»¬æŠŠ è®­ç»ƒé›† å’Œ éªŒè¯é›†åˆå¹¶æˆçº¦ 8 å°æ—¶çš„è®­ç»ƒæ•°æ®ï¼Œè€Œæµ‹è¯•åˆ™åŸºäº 4 å°æ—¶çš„ æµ‹è¯•é›†:

from datasets import load_dataset, DatasetDict

common_voice = DatasetDict()

common_voice["train"] = load_dataset("mozilla-foundation/common_voice_11_0", "hi", split="train+validation", use_auth_token=True)
common_voice["test"] = load_dataset("mozilla-foundation/common_voice_11_0", "hi", split="test", use_auth_token=True)

print(common_voice)

å¤§#å¤šæ•° ASR æ•°æ®é›†ä»…åŒ…å«è¾“å…¥éŸ³é¢‘æ ·æœ¬ ( audio) å’Œç›¸åº”çš„è½¬å½•æ–‡æœ¬ ( sentence)ã€‚ Common Voice è¿˜åŒ…å«é¢å¤–çš„å…ƒä¿¡æ¯ï¼Œä¾‹å¦‚ accent å’Œ localeï¼Œåœ¨ ASR åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å¿½ç•¥è¿™äº›ä¿¡æ¯ã€‚ä¸ºäº†ä½¿ä»£ç å°½å¯èƒ½é€šç”¨ï¼Œæˆ‘ä»¬åªè€ƒè™‘åŸºäºè¾“å…¥éŸ³é¢‘å’Œè½¬å½•æ–‡æœ¬è¿›è¡Œå¾®è°ƒï¼Œè€Œä¸ä½¿ç”¨é¢å¤–çš„å…ƒä¿¡æ¯:

common_voice = common_voice.remove_columns(["accent", "age", "client_id", "down_votes", "gender", "locale", "path", "segment", "up_votes"])

#Transformers Whisper ç‰¹å¾æå–å™¨ä»…ç”¨ä¸€è¡Œä»£ç å³å¯æ‰§è¡Œå¡«å……å’Œå£°è°±å›¾å˜æ¢ä¸¤ä¸ªæ“ä½œï¼æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç ä»é¢„è®­ç»ƒçš„ checkpoint ä¸­åŠ è½½ç‰¹å¾æå–å™¨ï¼Œä¸ºéŸ³é¢‘æ•°æ®å¤„ç†åšå¥½å‡†å¤‡.æˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¹ Common Voice æ•°æ®é›†çš„ç¬¬ä¸€ä¸ªæ ·æœ¬è¿›è¡Œç¼–è§£ç æ¥éªŒè¯åˆ†è¯å™¨æ˜¯å¦æ­£ç¡®ç¼–ç äº†å°åœ°è¯­å­—ç¬¦ã€‚
#åœ¨å¯¹è½¬å½•æ–‡æœ¬è¿›è¡Œç¼–ç æ—¶ï¼Œåˆ†è¯å™¨åœ¨åºåˆ—çš„å¼€å¤´å’Œç»“å°¾æ·»åŠ â€œç‰¹æ®Šæ ‡è®°â€ï¼Œå…¶ä¸­åŒ…æ‹¬æ–‡æœ¬çš„å¼€å§‹/ç»“å°¾ã€è¯­ç§æ ‡è®°å’Œä»»åŠ¡æ ‡è®° (ç”±ä¸Šä¸€æ­¥ä¸­çš„å‚æ•°æŒ‡å®š)ã€‚åœ¨è§£ç æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©â€œè·³è¿‡â€è¿™äº›ç‰¹æ®Šæ ‡è®°ï¼Œä»è€Œä¿è¯è¾“å‡ºæ˜¯çº¯æ–‡æœ¬å½¢å¼çš„:

from transformers import WhisperFeatureExtractor, WhisperTokenizer

feature_extractor = WhisperFeatureExtractor.from_pretrained("openai/whisper-small")
tokenizer = WhisperTokenizer.from_pretrained("openai/whisper-small", language="Hindi", task="transcribe")
input_str = common_voice["train"][0]["sentence"]
labels = tokenizer(input_str).input_ids
decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)
decoded_str = tokenizer.decode(labels, skip_special_tokens=True)

print(f"Input: {input_str}")
print(f"Decoded w/ special: {decoded_with_special}")
print(f"Decoded w/out special: {decoded_str}")
print(f"Are equal: {input_str == decoded_str}")

#ä¸ºäº†ç®€åŒ–ä½¿ç”¨ï¼Œæˆ‘ä»¬å¯ä»¥å°†ç‰¹å¾æå–å™¨å’Œåˆ†è¯å™¨ åŒ…è¿› åˆ°ä¸€ä¸ª WhisperProcessor ç±»ï¼Œè¯¥ç±»ç»§æ‰¿è‡ª WhisperFeatureExtractor åŠ WhisperTokenizerï¼Œå¯æ ¹æ®éœ€è¦ç”¨äºéŸ³é¢‘å¤„ç†å’Œæ¨¡å‹é¢„æµ‹ã€‚
from transformers import WhisperProcessor
processor = WhisperProcessor.from_pretrained("openai/whisper-small", language="Hindi", task="transcribe")
print(common_voice["train"][0])

#æˆ‘ä»¬å°†ä½¿ç”¨ dataset çš„ cast_column æ–¹æ³•å°†è¾“å…¥éŸ³é¢‘è½¬æ¢è‡³æ‰€éœ€çš„é‡‡æ ·ç‡ã€‚è¯¥æ–¹æ³•ä»…æŒ‡ç¤º datasets è®©å…¶åœ¨é¦–æ¬¡åŠ è½½éŸ³é¢‘æ—¶ _å³æ—¶åœ°_å¯¹æ•°æ®è¿›è¡Œé‡é‡‡æ ·ï¼Œå› æ­¤å¹¶ä¸ä¼šæ”¹å˜åŸéŸ³é¢‘æ•°æ®:

from datasets import Audio
common_voice = common_voice.cast_column("audio", Audio(sampling_rate=16000))

#é‡æ–°æ‰“å°ä¸‹ Common Voice æ•°æ®é›†ä¸­çš„ç¬¬ä¸€ä¸ªéŸ³é¢‘æ ·æœ¬ï¼Œå¯ä»¥çœ‹åˆ°å…¶å·²è¢«é‡é‡‡æ ·:

print(common_voice["train"][0])

# æˆ‘ä»¬å°†ä½¿ç”¨ dataset çš„ cast_column æ–¹æ³•å°†è¾“å…¥éŸ³é¢‘è½¬æ¢è‡³æ‰€éœ€çš„é‡‡æ ·ç‡ã€‚
# è¯¥æ–¹æ³•ä»…æŒ‡ç¤º datasets è®©å…¶åœ¨é¦–æ¬¡åŠ è½½éŸ³é¢‘æ—¶ _å³æ—¶åœ°_å¯¹æ•°æ®è¿›è¡Œé‡é‡‡æ ·ï¼Œå› æ­¤å¹¶ä¸ä¼šæ”¹å˜åŸéŸ³é¢‘æ•°æ®:

from datasets import Audio
common_voice = common_voice.cast_column("audio", Audio(sampling_rate=16000))
# é‡æ–°æ‰“å°ä¸‹ Common Voice æ•°æ®é›†ä¸­çš„ç¬¬ä¸€ä¸ªéŸ³é¢‘æ ·æœ¬ï¼Œå¯ä»¥çœ‹åˆ°å…¶å·²è¢«é‡é‡‡æ ·:
print(common_voice["train"][0])



#ç°åœ¨æˆ‘ä»¬ç¼–å†™ä¸€ä¸ªå‡½æ•°æ¥ä¸ºæ¨¡å‹å‡†å¤‡æ•°æ®:
def prepare_dataset(batch):
    # load and resample audio data from 48 to 16kHz
    audio = batch["audio"]

    # compute log-Mel input features from input audio array
    batch["input_features"] = feature_extractor(audio["array"], sampling_rate=audio["sampling_rate"]).input_features[0]

    # encode target text to label ids
    batch["labels"] = tokenizer(batch["sentence"]).input_ids
    return batch

common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names["train"], num_proc=4)
